{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1.13.2\n"
    }
   ],
   "source": "import tensorflow as tf\nprint(tf.__version__)\nimport os\nimport numpy as np"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### To load the image and preprocess"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": "def read_images(dataset_path):\n    global classes\n    im_path,labels=list(),list()\n    classes=os.listdir(dataset_path)\n    for i in classes:\n        path=os.path.join(dataset_path,i)\n        for j in os.listdir(path):\n            path1=os.path.join(path,j)\n            im_path.append(path1)\n            lab=classes.index(i)\n            if lab==0:\n                labels.append([0,1])\n            else:\n                labels.append([1,0])\n    for i in range(len(classes)):\n        print('{}:{}'.format(classes[i],i))\n    im_path=tf.convert_to_tensor(im_path)\n    labels=tf.convert_to_tensor(labels)\n    labels=tf.cast(labels,tf.float32)\n    image,labels=tf.train.slice_input_producer([im_path,labels],shuffle=True)\n    image = tf.read_file(image)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize_images(image, [32, 32])\n    # Normalize\n    image = image * 1.0/127.5 - 1.0\n    X, Y = tf.train.batch([image, labels], batch_size=32,capacity=32 * 8,num_threads=4)\n    return X,Y"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "stone:0\npaper:1\nWARNING:tensorflow:From <ipython-input-2-ccd36fab4ff2>:20: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\nInstructions for updating:\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\nWARNING:tensorflow:From /home/cocoslabs/anaconda3/lib/python2.7/site-packages/tensorflow/python/training/input.py:374: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\nInstructions for updating:\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\nWARNING:tensorflow:From /home/cocoslabs/anaconda3/lib/python2.7/site-packages/tensorflow/python/training/input.py:320: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\nInstructions for updating:\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\nWARNING:tensorflow:From /home/cocoslabs/anaconda3/lib/python2.7/site-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\nInstructions for updating:\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\nWARNING:tensorflow:From /home/cocoslabs/anaconda3/lib/python2.7/site-packages/tensorflow/python/training/input.py:199: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module.\nWARNING:tensorflow:From /home/cocoslabs/anaconda3/lib/python2.7/site-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module.\nWARNING:tensorflow:From /home/cocoslabs/anaconda3/lib/python2.7/site-packages/tensorflow/python/training/input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nWARNING:tensorflow:From <ipython-input-2-ccd36fab4ff2>:26: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\nInstructions for updating:\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
    }
   ],
   "source": "dataset_path='dataset/train/'   #give the dataset path\nX,Y=read_images(dataset_path)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### CNN Architecture\n\n1.conv layer 3x3 32 filters\n\n2.conv layer 3 x3 64 filters\n\n3.dense layer 120 neurons\n\n4.dense layer 2 neurons\n"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": "def getModel(x,re=False):\n    print(x.shape)\n    with tf.variable_scope('conv1',reuse=re) as scope:\n        w=tf.get_variable('w',shape=[3,3,3,32],initializer=tf.contrib.layers.xavier_initializer())\n        b=tf.get_variable('b',initializer=tf.zeros([32]))\n        l1=tf.nn.conv2d(x,w,strides=[1,1,1,1],padding='VALID')\n        l1_b=tf.nn.bias_add(l1,b)\n        l1_act=tf.nn.relu(l1_b)\n    print(l1_act)\n    with tf.variable_scope('conv2',reuse=re) as scope:\n        w=tf.get_variable('w',shape=[3,3,32,64],initializer=tf.contrib.layers.xavier_initializer())\n        b=tf.get_variable('b',initializer=tf.zeros([64]))\n        l2=tf.nn.conv2d(l1_act,w,strides=[1,1,1,1],padding='VALID')\n        l2_b=tf.nn.bias_add(l2,b)\n        l2_act=tf.nn.relu(l2_b)\n    l3_max=tf.nn.max_pool(l2_act,[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n    print(l3_max.shape)\n    with tf.variable_scope('dense1',reuse=re) as scope:\n        w=tf.get_variable('w',shape=[14*14*64,120],initializer=tf.contrib.layers.xavier_initializer())\n        b=tf.get_variable('b',initializer=tf.zeros([120]))\n        l4=tf.reshape(l3_max,[32,14*14*64])\n        print('l4',l4.shape)\n        l4=tf.matmul(l4,w)\n        l4_b=tf.nn.bias_add(l4,b)\n        l4_act=tf.nn.relu(l4_b)\n    with tf.variable_scope('dense2',reuse=re) as scope:\n        w=tf.get_variable('w',shape=[120,2],initializer=tf.contrib.layers.xavier_initializer())\n        b=tf.get_variable('b',initializer=tf.zeros(2))\n        l5=tf.matmul(l4_act,w)+b\n    print(l5)\n    \n    return l5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Load model Architecture"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(32, 32, 32, 3)\n\nWARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\nIf you depend on functionality not listed there, please file an issue.\n\nWARNING:tensorflow:From /home/cocoslabs/anaconda3/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nTensor(\"conv1/Relu:0\", shape=(32, 30, 30, 32), dtype=float32)\n(32, 14, 14, 64)\n('l4', TensorShape([Dimension(32), Dimension(12544)]))\nTensor(\"dense2/add:0\", shape=(32, 2), dtype=float32)\n(32, 32, 32, 3)\nTensor(\"conv1_1/Relu:0\", shape=(32, 30, 30, 32), dtype=float32)\n(32, 14, 14, 64)\n('l4', TensorShape([Dimension(32), Dimension(12544)]))\nTensor(\"dense2_1/add:0\", shape=(32, 2), dtype=float32)\n"
    }
   ],
   "source": "model_tr=getModel(X,re=False)   # if re is Fasle it initialize new value to the variables\nmodel_te=getModel(X,re=True)    # if re is True it takes the already initialized values"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Optimizer and Loss"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From <ipython-input-6-45cc44f15c80>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee `tf.nn.softmax_cross_entropy_with_logits_v2`.\n\n"
    }
   ],
   "source": "eval_pred=tf.nn.softmax(model_tr)\nval=tf.nn.softmax_cross_entropy_with_logits(logits=model_tr,labels=Y)\ncost=tf.reduce_mean(val)\ntrain_op=tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Testing"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": "a=tf.argmax(model_te,1)\nb=tf.argmax(Y,1)\ncorrect_pred=tf.equal(a,b)"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Save Model\nCreate a folder with the name of \"model\" in your working directory "
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": "saver = tf.train.Saver()"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From <ipython-input-10-964c90de799d>:5: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nTo construct input pipelines, use the `tf.data` module.\n1/5 Iteration:0 Loss: 1.096 Accuracy : 0.3125\n1/5 Iteration:50 Loss: 0.010 Accuracy : 1.0\n1/5 Iteration:100 Loss: 0.055 Accuracy : 0.9375\n1/5 Iteration:150 Loss: 0.001 Accuracy : 1.0\n1/5 Iteration:200 Loss: 0.032 Accuracy : 1.0\n2/5 Iteration:0 Loss: 0.000 Accuracy : 0.96875\n2/5 Iteration:50 Loss: 0.003 Accuracy : 1.0\n2/5 Iteration:100 Loss: 0.001 Accuracy : 0.96875\n2/5 Iteration:150 Loss: 0.003 Accuracy : 1.0\n2/5 Iteration:200 Loss: 0.000 Accuracy : 1.0\n3/5 Iteration:0 Loss: 0.003 Accuracy : 1.0\n3/5 Iteration:50 Loss: 0.000 Accuracy : 1.0\n3/5 Iteration:100 Loss: 0.000 Accuracy : 1.0\n3/5 Iteration:150 Loss: 0.000 Accuracy : 1.0\n3/5 Iteration:200 Loss: 0.000 Accuracy : 1.0\n4/5 Iteration:0 Loss: 0.000 Accuracy : 1.0\n4/5 Iteration:50 Loss: 0.000 Accuracy : 1.0\n4/5 Iteration:100 Loss: 0.000 Accuracy : 1.0\n4/5 Iteration:150 Loss: 0.000 Accuracy : 1.0\n4/5 Iteration:200 Loss: 0.000 Accuracy : 1.0\n5/5 Iteration:0 Loss: 0.000 Accuracy : 1.0\n5/5 Iteration:50 Loss: 0.000 Accuracy : 1.0\n5/5 Iteration:100 Loss: 0.000 Accuracy : 1.0\n5/5 Iteration:150 Loss: 0.000 Accuracy : 1.0\n5/5 Iteration:200 Loss: 0.000 Accuracy : 1.0\n"
    }
   ],
   "source": "ite=6466//32  # total no. of image divided by batch size\nepoch=5  # epoch size\nwith tf.Session() as sess:\n    coord=tf.train.Coordinator()\n    threads=tf.train.start_queue_runners(coord=coord)\n    sess.run(tf.global_variables_initializer())\n    for epo in range(epoch):\n        for it in range(ite):\n            sess.run(train_op)\n            if it%50 ==0:\n                loss=sess.run(cost)\n                acc=sess.run(accuracy)\n                print('{}/{} Iteration:{} Loss: {:.3f} Accuracy : {}'.format(epo+1,epoch,it,loss,acc))\n    saver.save(sess,'model/my_test_model')  # save model\n    coord.request_stop()\n    coord.join(threads)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Restore the saved model "
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From /home/cocoslabs/anaconda3/lib/python2.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse standard file APIs to check for files with this prefix.\nINFO:tensorflow:Restoring parameters from model/my_test_model\n<tf.Variable 'conv1/w:0' shape=(3, 3, 3, 32) dtype=float32_ref>\n<tf.Variable 'conv1/b:0' shape=(32,) dtype=float32_ref>\n<tf.Variable 'conv2/w:0' shape=(3, 3, 32, 64) dtype=float32_ref>\n<tf.Variable 'conv2/b:0' shape=(64,) dtype=float32_ref>\n<tf.Variable 'dense1/w:0' shape=(12544, 120) dtype=float32_ref>\n<tf.Variable 'dense1/b:0' shape=(120,) dtype=float32_ref>\n<tf.Variable 'dense2/w:0' shape=(120, 2) dtype=float32_ref>\n<tf.Variable 'dense2/b:0' shape=(2,) dtype=float32_ref>\n<tf.Variable 'conv1/w:0' shape=(3, 3, 3, 32) dtype=float32_ref>\n<tf.Variable 'conv1/b:0' shape=(32,) dtype=float32_ref>\n<tf.Variable 'conv2/w:0' shape=(3, 3, 32, 64) dtype=float32_ref>\n<tf.Variable 'conv2/b:0' shape=(64,) dtype=float32_ref>\n<tf.Variable 'dense1/w:0' shape=(12544, 120) dtype=float32_ref>\n<tf.Variable 'dense1/b:0' shape=(120,) dtype=float32_ref>\n<tf.Variable 'dense2/w:0' shape=(120, 2) dtype=float32_ref>\n<tf.Variable 'dense2/b:0' shape=(2,) dtype=float32_ref>\n"
    }
   ],
   "source": "with tf.Session() as sess:    \n    saver = tf.train.import_meta_graph('model/my_test_model.meta')\n    saver.restore(sess,tf.train.latest_checkpoint('model/'))\n    for i in tf.trainable_variables():\n        print(i)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
